{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc1a094a-bb0b-44ba-bc6f-dceb4a7b7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import click\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "import torch\n",
    "import dnnlib\n",
    "\n",
    "from training import training_loop\n",
    "from metrics import metric_main\n",
    "from torch_utils import training_stats\n",
    "from torch_utils import custom_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141e9081-8a96-4eb8-8d4d-3ec1102609d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# Stylegan2 configuration\n",
    "# =======================================================\n",
    "#    python train.py --outdir=./training-runs \\\n",
    "#                    --data=./datasets/ffhq.zip \\\n",
    "#                    --gpus=8 \\\n",
    "#                    --cfg=stylegan2 \\\n",
    "#                    --mirror=1 \\\n",
    "#                    --aug=noaug\n",
    "args = dnnlib.EasyDict()\n",
    "args.num_gpus = 8\n",
    "args.image_snapshot_ticks = 50\n",
    "args.network_snapshot_ticks = 50\n",
    "args.metrics = ['fid50k_full']\n",
    "args.random_seed = 0\n",
    "args.training_set_kwargs = dnnlib.EasyDict(class_name='training.dataset.ImageFolderDataset', \n",
    "                                           path='./datasets/ffhq.zip', \n",
    "                                           use_labels=True, \n",
    "                                           max_size=None, \n",
    "                                           xflip=False)\n",
    "args.data_loader_kwargs = dnnlib.EasyDict(pin_memory=True, \n",
    "                                          num_workers=3, \n",
    "                                          prefetch_factor=2)\n",
    "args.training_set_kwargs.resolution  = 1024\n",
    "desc = 'ffhq' # training_set.name\n",
    "args.training_set_kwargs.use_labels = True\n",
    "args.training_set_kwargs.max_size = 70000\n",
    "args.training_set_kwargs.use_labels = False # -cond False\n",
    "args.training_set_kwargs.random_seed = args.random_seed\n",
    "desc += '-mirror' # # mirrory=1\n",
    "args.training_set_kwargs.xflip = True  # mirrory=1\n",
    "cfg = 'stylegan2'\n",
    "desc += f'-{cfg}'\n",
    "cfg_specs = {\n",
    "    'auto':      dict(ref_gpus=-1, kimg=25000,  mb=-1, mbstd=-1, fmaps=-1,  lrate=-1,     gamma=-1,   ema=-1,  ramp=0.05, map=2), # Populated dynamically based on resolution and GPU count.\n",
    "    'stylegan2': dict(ref_gpus=8,  kimg=25000,  mb=32, mbstd=4,  fmaps=1,   lrate=0.002,  gamma=10,   ema=10,  ramp=None, map=8), # Uses mixed-precision, unlike the original StyleGAN2.\n",
    "    'paper256':  dict(ref_gpus=8,  kimg=25000,  mb=64, mbstd=8,  fmaps=0.5, lrate=0.0025, gamma=1,    ema=20,  ramp=None, map=8),\n",
    "    'paper512':  dict(ref_gpus=8,  kimg=25000,  mb=64, mbstd=8,  fmaps=1,   lrate=0.0025, gamma=0.5,  ema=20,  ramp=None, map=8),\n",
    "    'paper1024': dict(ref_gpus=8,  kimg=25000,  mb=32, mbstd=4,  fmaps=1,   lrate=0.002,  gamma=2,    ema=10,  ramp=None, map=8),\n",
    "    'cifar':     dict(ref_gpus=2,  kimg=100000, mb=64, mbstd=32, fmaps=1,   lrate=0.0025, gamma=0.01, ema=500, ramp=0.05, map=2),\n",
    "}\n",
    "spec = dnnlib.EasyDict(cfg_specs[cfg])\n",
    "args.G_kwargs = dnnlib.EasyDict(class_name='training.networks.Generator', z_dim=512, w_dim=512, mapping_kwargs=dnnlib.EasyDict(), synthesis_kwargs=dnnlib.EasyDict())\n",
    "args.D_kwargs = dnnlib.EasyDict(class_name='training.networks.Discriminator', block_kwargs=dnnlib.EasyDict(), mapping_kwargs=dnnlib.EasyDict(), epilogue_kwargs=dnnlib.EasyDict())\n",
    "args.G_kwargs.synthesis_kwargs.channel_base = args.D_kwargs.channel_base = int(spec.fmaps * 32768)\n",
    "args.G_kwargs.synthesis_kwargs.channel_max = args.D_kwargs.channel_max = 512\n",
    "args.G_kwargs.mapping_kwargs.num_layers = spec.map\n",
    "args.G_kwargs.synthesis_kwargs.num_fp16_res = args.D_kwargs.num_fp16_res = 4 # enable mixed-precision training\n",
    "args.G_kwargs.synthesis_kwargs.conv_clamp = args.D_kwargs.conv_clamp = 256 # clamp activations to avoid float16 overflow\n",
    "args.D_kwargs.epilogue_kwargs.mbstd_group_size = spec.mbstd\n",
    "\n",
    "args.G_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', lr=spec.lrate, betas=[0,0.99], eps=1e-8)\n",
    "args.D_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', lr=spec.lrate, betas=[0,0.99], eps=1e-8)\n",
    "args.loss_kwargs = dnnlib.EasyDict(class_name='training.loss.StyleGAN2Loss', r1_gamma=spec.gamma)\n",
    "\n",
    "\n",
    "args.total_kimg = spec.kimg\n",
    "args.batch_size = spec.mb\n",
    "args.batch_gpu = spec.mb // spec.ref_gpus\n",
    "args.ema_kimg = spec.ema\n",
    "args.ema_rampup = spec.ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e61db37-ff63-426f-9318-1eb424199b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D_kwargs': {'block_kwargs': {},\n",
      "              'channel_base': 32768,\n",
      "              'channel_max': 512,\n",
      "              'class_name': 'training.networks.Discriminator',\n",
      "              'conv_clamp': 256,\n",
      "              'epilogue_kwargs': {'mbstd_group_size': 4},\n",
      "              'mapping_kwargs': {},\n",
      "              'num_fp16_res': 4},\n",
      " 'D_opt_kwargs': {'betas': [0, 0.99],\n",
      "                  'class_name': 'torch.optim.Adam',\n",
      "                  'eps': 1e-08,\n",
      "                  'lr': 0.002},\n",
      " 'G_kwargs': {'class_name': 'training.networks.Generator',\n",
      "              'mapping_kwargs': {'num_layers': 8},\n",
      "              'synthesis_kwargs': {'channel_base': 32768,\n",
      "                                   'channel_max': 512,\n",
      "                                   'conv_clamp': 256,\n",
      "                                   'num_fp16_res': 4},\n",
      "              'w_dim': 512,\n",
      "              'z_dim': 512},\n",
      " 'G_opt_kwargs': {'betas': [0, 0.99],\n",
      "                  'class_name': 'torch.optim.Adam',\n",
      "                  'eps': 1e-08,\n",
      "                  'lr': 0.002},\n",
      " 'batch_gpu': 4,\n",
      " 'batch_size': 32,\n",
      " 'data_loader_kwargs': {'num_workers': 3,\n",
      "                        'pin_memory': True,\n",
      "                        'prefetch_factor': 2},\n",
      " 'ema_kimg': 10,\n",
      " 'ema_rampup': None,\n",
      " 'image_snapshot_ticks': 50,\n",
      " 'loss_kwargs': {'class_name': 'training.loss.StyleGAN2Loss', 'r1_gamma': 10},\n",
      " 'metrics': ['fid50k_full'],\n",
      " 'network_snapshot_ticks': 50,\n",
      " 'num_gpus': 8,\n",
      " 'random_seed': 0,\n",
      " 'total_kimg': 25000,\n",
      " 'training_set_kwargs': {'class_name': 'training.dataset.ImageFolderDataset',\n",
      "                         'max_size': 70000,\n",
      "                         'path': './datasets/ffhq.zip',\n",
      "                         'random_seed': 0,\n",
      "                         'resolution': 1024,\n",
      "                         'use_labels': False,\n",
      "                         'xflip': True}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "834778a2-d03f-48e2-8214-bef6f51fc18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ffhq-mirror-stylegan2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d17bf54-fda8-4aaf-82b9-d911457c50c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31e668b9-3986-4775-b404-e103c92e3d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3519279-00b1-4157-9a9a-2c34ec01e943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuda:0': 'cuda:1'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = 1\n",
    "map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}\n",
    "map_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4a04d91-0bb6-49f7-8d61-6634739b4ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba794f-d403-48c8-95fb-88ddf34fad6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
